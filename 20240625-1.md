## Decsion Tree
```python
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

X = DF.iloc[:,7:]
y = DF.label
```


```python
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

# 创建一个ColumnTransformer对象，并指定哪些列是分类变量   # 分类特征对应的列索引为0
# remainder参数设置为'passthrough'，表示保留未指定的列
column_transformer = ColumnTransformer(
    transformers=[('encoder', OneHotEncoder(), X.columns[0:1].append(X.columns[8:]).values )],
    remainder='passthrough')
# 对数据进行转换
X_encoded = column_transformer.fit_transform(X)
#column_transformer.get_feature_names()
#column_transformer.named_transformers_['encoder'].get_feature_names(X.columns[0:1].append(X.columns[8:]).values)
feature_names_ = np.concatenate([column_transformer.named_transformers_['encoder'].get_feature_names(X.columns[0:1].append(X.columns[8:]).values),column_transformer.get_feature_names()[71:] ])

```

```python
# 划分为训练集和测试集
#X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)
# 先将原始数据集分为训练集和剩余部分
X_train, X_remain, y_train, y_remain = train_test_split(X_encoded, y, test_size=0.3, random_state=42)

# 再将剩余部分分为测试集和验证集
X_test, X_val, y_test, y_val = train_test_split(X_remain, y_remain, test_size=0.5, random_state=42)

```



```python
# 创建决策树分类器
classifier = DecisionTreeClassifier()

# 训练模型
classifier.fit(X_train, y_train)
```


```python
# 在测试集上进行预测
y_pred = classifier.predict(X_test)
# 在测试集上进行预测概率
y_pred_proba = classifier.predict_proba(X_test)

```


```python
# 打印预测结果
print("预测结果：")
for i in range(20):  #len(X_test)
    print(f"样本 {i+1}: 预测类别为 {y_pred[i]}, 实际类别为 {y_test.iloc[i]}")
```

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# 打印评估指标
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
```

```python
from sklearn.metrics import confusion_matrix
# 计算混淆矩阵
cm = confusion_matrix(y_test, y_pred)

```

```python
fig, ax = plt.subplots(figsize=(20, 8))

sns.heatmap(pd.DataFrame((cm/len(y_test)).round(5)), cmap='coolwarm', annot=True, fmt='.5f')

# 添加标题和坐标轴标签
plt.title('Heatmap')
plt.xlabel('X-axis')
plt.ylabel('Y-axis')

# 显示热力图
plt.show()
```

```python
from sklearn.metrics import classification_report

target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6', 'class 7', 'class 8', 'class 9', 'class 10', 'class 11', 'class 12', 'class 13', 'class 14', 'class 15', 'class 16', 'class 17', 'class 18']
print(classification_report(y_test, y_pred ))#target_names=target_names

```

```python
from sklearn.metrics import log_loss, average_precision_score
from sklearn.preprocessing import LabelBinarizer

# 创建LabelBinarizer对象
binarizer = LabelBinarizer()

# 将类别标签转换为二进制数组形式
y_test_bin = binarizer.fit_transform(y_test)

# 使用log_loss评估模型多分类概率预测值
logloss = log_loss(y_test_bin, y_pred_proba)
print("Log Loss:", logloss)

# 使用average_precision_score评估模型多分类概率预测值
avg_precision = average_precision_score(y_test_bin, y_pred_proba, average='weighted')
print("Average Precision Score:", avg_precision)
```

```python
from sklearn import tree
import matplotlib.pyplot as plt
# 可视化决策树
fig, ax = plt.subplots(figsize=(40, 20))
tree.plot_tree(classifier, filled=True, feature_names=feature_names_,  max_depth=3,ax=ax,proportion=True,fontsize=14) #class_names=data.target_names,

plt.show()
```


```python
from dtreeviz.trees import dtreeviz
# 可视化决策树
viz = dtreeviz(clf, X_test, y, feature_names=feature_names_, class_names=data.target_names)
viz.save("decision_tree.svg")  #将决策树保存为SVG文件
viz.view()  #展示决策树
```

```python
import xgboost as xgb
from sklearn.metrics import accuracy_score
# 构建XGBoost模型
model = xgb.XGBClassifier(booster='gbtree', objective='multi:softmax', num_class=19,
                          colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_delta_step=0,
                          max_depth=5, min_child_weight=0, n_estimators=100, n_jobs=7,
                          random_state=0, colsample_bylevel=0.7, tree_method='hist',
                          alpha=2, subsample=0.7,early_stopping_rounds=10,verbose=True)

# 训练模型
model.fit(X_train, y_train, eval_set=[X_val,y_val])

# 在测试集上进行预测
y_pred = model.predict(X_test)

# 计算准确率
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

# 获取特征重要性
feature_importance = model.feature_importances_

# 绘制特征重要性图
plt.bar(range(len(feature_importance)), feature_importance)
plt.xticks(range(len(feature_importance)), feature_names_, rotation=45)
plt.xlabel("Features")
plt.ylabel("Importance")
plt.title("Feature Importance")
plt.show()

importance_col = pd.DataFrame([*zip(feature_names_, feature_importance)], columns=['name', 'importance'])
importance_col_desc = importance_col.sort_values(by='importance', ascending=False)
importance_col_desc['cumsum']=importance_col_desc.cumsum()['importance']
```



